# DecAlign: Hierarchical Cross-Modal Alignment for Decoupled Multimodal Representation Learning

Authors: [Chengxuan Qian](https://qiancx.com/), [Shuo Xing](https://shuoxing98.github.io/),

DecAlign introduces a hierarchical cross-modal alignment framework to enhance multimodal representation learning. By decoupling modality-unique (heterogeneous) and modality-common (homogeneous) features, it employs prototype-based optimal transport and MMD regularization for fine-grained cross-modal alignment, effectively mitigating modality interference and enhancing semantic consistency. Extensive experiments demonstrate that DecAlign consistently outperforms state-of-the-art methods across multiple benchmarks. Its novel approach establishes a new paradigm for multimodal learning, providing a solid foundation for advancing cross-modal information integration and alignment in academic research.

## Prepare Datasets
